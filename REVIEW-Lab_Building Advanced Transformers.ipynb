{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Lab: Building Advanced Transformers**\n",
    "\n",
    "**Estimated time needed:  30 minutes**  \n",
    "\n",
    "In this lab, you will implement and experiment with advanced Transformer models using Keras. \n",
    "\n",
    "**Learning objectives:** \n",
    "\n",
    "By the end of this lab, you will be able to:\n",
    "\n",
    "- Understand the core components of a Transformer architecture.\n",
    "- Implement a multi-head self-attention mechanism from scratch.\n",
    "- Train and evaluate a Transformer for time series prediction.\n",
    "- Handle preprocessing and scaling for time series data effectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a Transformer?\n",
    "\n",
    "The Transformer architecture was introduced in the paper *\"Attention Is All You Need\"*. It revolutionized natural language processing by using attention mechanisms instead of recurrence.\n",
    "\n",
    "### Key Components:\n",
    "- **Input Embedding:** Converts input tokens (or time steps) into vectors.\n",
    "- **Positional Encoding:** Injects information about the position of input tokens.\n",
    "- **Multi-Head Self-Attention:** Allows the model to focus on different parts of the input sequence.\n",
    "- **Feedforward Layers:** Process the attended information.\n",
    "- **Layer Normalization & Residual Connections:** Stabilize and speed up training.\n",
    "\n",
    "> Transformers are now widely used not only in NLP but also in time series forecasting, image recognition, and more.\n",
    "\n",
    "**Next:** You will implement parts of this architecture step-by-step.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-by-Step Instructions: \n",
    "\n",
    "### Step 1: Import necessary libraries \n",
    "\n",
    "Before you start, you need to import the required libraries: TensorFlow and Keras. Keras is included within TensorFlow as `tensorflow.keras.`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\n",
      "Collecting pyarrow\n",
      "  Downloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google_pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting opt_einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.12/site-packages (from tensorflow) (24.2)\n",
      "Collecting protobuf>=5.28.0 (from tensorflow)\n",
      "  Downloading protobuf-6.33.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from tensorflow) (75.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-3.2.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (4.12.2)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Downloading wrapt-2.0.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (9.0 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.76.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.7 kB)\n",
      "Collecting tensorboard~=2.20.0 (from tensorflow)\n",
      "  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.10.0 (from tensorflow)\n",
      "  Downloading keras-3.12.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting numpy>=1.26.0 (from tensorflow)\n",
      "  Downloading numpy-2.3.5-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
      "Collecting h5py>=3.11.0 (from tensorflow)\n",
      "  Downloading h5py-3.15.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting ml_dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.5.4-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Collecting rich (from keras>=3.10.0->tensorflow)\n",
      "  Downloading rich-14.2.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.10.0->tensorflow)\n",
      "  Downloading namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.10.0->tensorflow)\n",
      "  Downloading optree-0.18.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (34 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading markdown-3.10-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting pillow (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading pillow-12.0.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.10.0->tensorflow)\n",
      "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.12/site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading tensorflow-2.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (620.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m620.7/620.7 MB\u001b[0m \u001b[31m944.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Downloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (47.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.76.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading h5py-3.15.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading keras-3.12.0-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.5.4-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (5.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.3.5-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading protobuf-6.33.1-cp39-abi3-manylinux2014_x86_64.whl (323 kB)\n",
      "Downloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-3.2.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading wrapt-2.0.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (121 kB)\n",
      "Downloading markdown-3.10-py3-none-any.whl (107 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading optree-0.18.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (408 kB)\n",
      "Downloading pillow-12.0.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rich-14.2.0-py3-none-any.whl (243 kB)\n",
      "Downloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, werkzeug, termcolor, tensorboard-data-server, pyarrow, protobuf, pillow, optree, opt_einsum, numpy, mdurl, markdown, grpcio, google_pasta, gast, astunparse, absl-py, tensorboard, ml_dtypes, markdown-it-py, h5py, rich, keras, tensorflow\n",
      "Successfully installed absl-py-2.3.1 astunparse-1.6.3 flatbuffers-25.9.23 gast-0.6.0 google_pasta-0.2.0 grpcio-1.76.0 h5py-3.15.1 keras-3.12.0 libclang-18.1.1 markdown-3.10 markdown-it-py-4.0.0 mdurl-0.1.2 ml_dtypes-0.5.4 namex-0.1.0 numpy-2.3.5 opt_einsum-3.4.0 optree-0.18.0 pillow-12.0.0 protobuf-6.33.1 pyarrow-22.0.0 rich-14.2.0 tensorboard-2.20.0 tensorboard-data-server-0.7.2 tensorflow-2.20.0 termcolor-3.2.0 werkzeug-3.1.3 wrapt-2.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.3.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m153.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: tzdata, pandas\n",
      "Successfully installed pandas-2.3.3 tzdata-2025.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.7.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn) (2.3.5)\n",
      "Collecting scipy>=1.8.0 (from scikit-learn)\n",
      "  Downloading scipy-1.16.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (62 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.7.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m142.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Downloading scipy-1.16.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.7/35.7 MB\u001b[0m \u001b[31m140.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.5.2 scikit-learn-1.7.2 scipy-1.16.3 threadpoolctl-3.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.7-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.60.1-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (112 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.9-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (2.3.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (12.0.0)\n",
      "Collecting pyparsing>=3 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.5-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Downloading matplotlib-3.10.7-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m129.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (362 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.60.1-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m127.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.9-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m96.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.2.5-py3-none-any.whl (113 kB)\n",
      "Installing collected packages: pyparsing, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.3 cycler-0.12.1 fonttools-4.60.1 kiwisolver-1.4.9 matplotlib-3.10.7 pyparsing-3.2.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.12/site-packages (2.32.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests) (2024.12.14)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow pyarrow \n",
    "%pip install pandas  \n",
    "%pip install scikit-learn \n",
    "%pip install matplotlib \n",
    "%pip install requests\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 10:19:03.158338: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-23 10:19:03.158784: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-23 10:19:03.220204: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-23 10:19:04.925240: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-23 10:19:04.925864: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import tensorflow as tf \n",
    "import requests\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from tensorflow.keras.layers import Layer, Dense, LayerNormalization, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Setup the Environment to generate synthetic stock price data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic stock_prices.csv created and loaded.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Create a synthetic stock price dataset\n",
    "np.random.seed(42)\n",
    "data_length = 2000  # Adjust data length as needed\n",
    "trend = np.linspace(100, 200, data_length)\n",
    "noise = np.random.normal(0, 2, data_length)\n",
    "synthetic_data = trend + noise\n",
    "\n",
    "# Create a DataFrame and save as 'stock_prices.csv'\n",
    "data = pd.DataFrame(synthetic_data, columns=['Close'])\n",
    "data.to_csv('stock_prices.csv', index=False)\n",
    "print(\"Synthetic stock_prices.csv created and loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (1899, 100, 1)\n",
      "Shape of Y: (1899,)\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset \n",
    "data = pd.read_csv('stock_prices.csv') \n",
    "data = data[['Close']].values \n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data = scaler.fit_transform(data)\n",
    "\n",
    "# Prepare the data for training\n",
    "def create_dataset(data, time_step=1):\n",
    "    X, Y = [], []\n",
    "\n",
    "    for i in range(len(data)-time_step-1):\n",
    "        a = data[i:(i+time_step), 0]\n",
    "        X.append(a)\n",
    "        Y.append(data[i + time_step, 0])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "time_step = 100\n",
    "X, Y = create_dataset(data, time_step)\n",
    "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "\n",
    "print(\"Shape of X:\", X.shape) \n",
    "print(\"Shape of Y:\", Y.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "`tensorflow` is the main library for machine learning in Python.  \n",
    "\n",
    "`stock_prices.csv` is the data set that is loaded. \n",
    "\n",
    "`MinMaxScaler` method is used to normalize the data.  \n",
    "\n",
    "`create_dataset`method is used to prepare the data for training. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Implement Multi-Head Self-Attention \n",
    "\n",
    "Define the Multi-Head Self-Attention mechanism. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadSelfAttention(Layer): \n",
    "\n",
    "    def __init__(self, embed_dim, num_heads=8): \n",
    "        super(MultiHeadSelfAttention, self).__init__() \n",
    "        self.embed_dim = embed_dim \n",
    "        self.num_heads = num_heads \n",
    "        self.projection_dim = embed_dim // num_heads \n",
    "        self.query_dense = Dense(embed_dim) \n",
    "        self.key_dense = Dense(embed_dim) \n",
    "        self.value_dense = Dense(embed_dim) \n",
    "        self.combine_heads = Dense(embed_dim) \n",
    "\n",
    "\n",
    "    def attention(self, query, key, value): \n",
    "        score = tf.matmul(query, key, transpose_b=True) \n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32) \n",
    "        scaled_score = score / tf.math.sqrt(dim_key) \n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1) \n",
    "        output = tf.matmul(weights, value) \n",
    "        return output, weights \n",
    "\n",
    "    def split_heads(self, x, batch_size): \n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim)) \n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3]) \n",
    "\n",
    "    def call(self, inputs): \n",
    "        batch_size = tf.shape(inputs)[0] \n",
    "        query = self.query_dense(inputs) \n",
    "        key = self.key_dense(inputs) \n",
    "        value = self.value_dense(inputs) \n",
    "        query = self.split_heads(query, batch_size) \n",
    "        key = self.split_heads(key, batch_size) \n",
    "        value = self.split_heads(value, batch_size) \n",
    "        attention, _ = self.attention(query, key, value) \n",
    "        attention = tf.transpose(attention, perm=[0, 2, 1, 3]) \n",
    "        concat_attention = tf.reshape(attention, (batch_size, -1, self.embed_dim)) \n",
    "        output = self.combine_heads(concat_attention) \n",
    "        return output \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "- The MultiHeadSelfAttention layer implements the multi-head self-attention mechanism, which allows the model to focus on different parts of the input sequence simultaneously. \n",
    "\n",
    "- The attention parameter computes the attention scores and weighted sum of the values. \n",
    "\n",
    "- The split_heads parameter splits the input into multiple heads for parallel attention computation. \n",
    "\n",
    "- The call method applies the self-attention mechanism and combines the heads. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Implement Transformer block \n",
    "\n",
    "Define the Transformer block. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(Layer): \n",
    "\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(TransformerBlock, self).__init__() \n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads) \n",
    "        self.ffn = tf.keras.Sequential([ \n",
    "            Dense(ff_dim, activation=\"relu\"), \n",
    "            Dense(embed_dim), \n",
    "        ]) \n",
    "\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6) \n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6) \n",
    "        self.dropout1 = Dropout(rate) \n",
    "        self.dropout2 = Dropout(rate) \n",
    "\n",
    "\n",
    "    def call(self, inputs, training): \n",
    "        attn_output = self.att(inputs) \n",
    "        attn_output = self.dropout1(attn_output, training=training) \n",
    "        out1 = self.layernorm1(inputs + attn_output) \n",
    "        ffn_output = self.ffn(out1) \n",
    "        ffn_output = self.dropout2(ffn_output, training=training) \n",
    "        return self.layernorm2(out1 + ffn_output) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code:\n",
    "\n",
    "- The TransformerBlock layer combines multi-head self-attention with a feed-forward neural network and normalization layers.  \n",
    "\n",
    "- Dropout is used to prevent overfitting. \n",
    "\n",
    "- The call method applies the self-attention, followed by the feedforward network with residual connections and layer normalization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Implement Encoder Layer \n",
    "\n",
    "Define the Encoder layer. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(Layer): \n",
    "\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(EncoderLayer, self).__init__() \n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads) \n",
    "        self.ffn = tf.keras.Sequential([ \n",
    "            Dense(ff_dim, activation=\"relu\"), \n",
    "            Dense(embed_dim), \n",
    "        ]) \n",
    "\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6) \n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6) \n",
    "        self.dropout1 = Dropout(rate) \n",
    "        self.dropout2 = Dropout(rate) \n",
    "\n",
    " \n",
    "\n",
    "    def call(self, inputs, training): \n",
    "        attn_output = self.att(inputs) \n",
    "        attn_output = self.dropout1(attn_output, training=training) \n",
    "        out1 = self.layernorm1(inputs + attn_output) \n",
    "        ffn_output = self.ffn(out1) \n",
    "        ffn_output = self.dropout2(ffn_output, training=training) \n",
    "        return self.layernorm2(out1 + ffn_output) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "- The EncoderLayer is similar to the TransformerBlock but is a reusable layer in the Transformer architecture. \n",
    "\n",
    "- It consists of a MultiHeadSelfAttention mechanism followed by a feedforward neural network. \n",
    "\n",
    "- Both sub-layers have residual connections around them, and layer normalization is applied to the output of each sub-layer. \n",
    "\n",
    "- The call method applies the self-attention, followed by the feedforward network, with residual connections and layer normalization. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Implement Transformer encoder \n",
    "\n",
    "Define the Transformer Encoder. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 10:19:28.088326: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 100, 128)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.layers import Layer, Dense, LayerNormalization, Dropout \n",
    "\n",
    "class MultiHeadSelfAttention(Layer): \n",
    "    def __init__(self, embed_dim, num_heads=8): \n",
    "        super(MultiHeadSelfAttention, self).__init__() \n",
    "        self.embed_dim = embed_dim \n",
    "        self.num_heads = num_heads \n",
    "        self.projection_dim = embed_dim // num_heads \n",
    "        self.query_dense = Dense(embed_dim) \n",
    "        self.key_dense = Dense(embed_dim) \n",
    "        self.value_dense = Dense(embed_dim) \n",
    "        self.combine_heads = Dense(embed_dim) \n",
    " \n",
    "\n",
    "    def attention(self, query, key, value): \n",
    "        score = tf.matmul(query, key, transpose_b=True) \n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32) \n",
    "        scaled_score = score / tf.math.sqrt(dim_key) \n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1) \n",
    "        output = tf.matmul(weights, value) \n",
    "        return output, weights \n",
    "\n",
    "\n",
    "    def split_heads(self, x, batch_size): \n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim)) \n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3]) \n",
    "\n",
    "\n",
    "    def call(self, inputs): \n",
    "        batch_size = tf.shape(inputs)[0] \n",
    "        query = self.query_dense(inputs) \n",
    "        key = self.key_dense(inputs) \n",
    "        value = self.value_dense(inputs) \n",
    "        query = self.split_heads(query, batch_size) \n",
    "        key = self.split_heads(key, batch_size) \n",
    "        value = self.split_heads(value, batch_size) \n",
    "        attention, _ = self.attention(query, key, value) \n",
    "        attention = tf.transpose(attention, perm=[0, 2, 1, 3]) \n",
    "        concat_attention = tf.reshape(attention, (batch_size, -1, self.embed_dim)) \n",
    "        output = self.combine_heads(concat_attention) \n",
    "        return output \n",
    "\n",
    "class TransformerBlock(Layer): \n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(TransformerBlock, self).__init__() \n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads) \n",
    "        self.ffn = tf.keras.Sequential([ \n",
    "            Dense(ff_dim, activation=\"relu\"), \n",
    "            Dense(embed_dim), \n",
    "        ]) \n",
    "\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6) \n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6) \n",
    "        self.dropout1 = Dropout(rate) \n",
    "        self.dropout2 = Dropout(rate) \n",
    " \n",
    "\n",
    "    def call(self, inputs, training): \n",
    "        attn_output = self.att(inputs) \n",
    "        attn_output = self.dropout1(attn_output, training=training) \n",
    "        out1 = self.layernorm1(inputs + attn_output) \n",
    "        ffn_output = self.ffn(out1) \n",
    "        ffn_output = self.dropout2(ffn_output, training=training) \n",
    "        return self.layernorm2(out1 + ffn_output) \n",
    "\n",
    "class TransformerEncoder(Layer): \n",
    "    def __init__(self, num_layers, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(TransformerEncoder, self).__init__() \n",
    "        self.num_layers = num_layers \n",
    "        self.embed_dim = embed_dim \n",
    "        self.enc_layers = [TransformerBlock(embed_dim, num_heads, ff_dim, rate) for _ in range(num_layers)] \n",
    "        self.dropout = Dropout(rate) \n",
    "\n",
    "    def call(self, inputs, training=False): \n",
    "        x = inputs \n",
    "        for i in range(self.num_layers): \n",
    "            x = self.enc_layers[i](x, training=training) \n",
    "        return x \n",
    "\n",
    "# Example usage \n",
    "embed_dim = 128 \n",
    "num_heads = 8 \n",
    "ff_dim = 512 \n",
    "num_layers = 4 \n",
    "\n",
    "transformer_encoder = TransformerEncoder(num_layers, embed_dim, num_heads, ff_dim) \n",
    "inputs = tf.random.uniform((1, 100, embed_dim)) \n",
    "outputs = transformer_encoder(inputs, training=False)  # Use keyword argument for 'training' \n",
    "print(outputs.shape)  # Should print (1, 100, 128) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "The TransformerEncoder is composed of multiple TransformerBlock layers, implementing the encoding part of the Transformer architecture. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Build and Compile the Transformer model \n",
    "\n",
    "Integrate the Transformer Encoder into a complete model for sequential data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">793,088</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12800</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,801</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_48 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │           \u001b[38;5;34m256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m793,088\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12800\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_49 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │        \u001b[38;5;34m12,801\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">806,145</span> (3.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m806,145\u001b[0m (3.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">806,145</span> (3.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m806,145\u001b[0m (3.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the necessary parameters \n",
    "\n",
    "embed_dim = 128 \n",
    "num_heads = 8 \n",
    "ff_dim = 512 \n",
    "num_layers = 4 \n",
    "\n",
    "# Define the Transformer Encoder \n",
    "transformer_encoder = TransformerEncoder(num_layers, embed_dim, num_heads, ff_dim) \n",
    "\n",
    "# Build the model \n",
    "input_shape = (X.shape[1], X.shape[2]) \n",
    "inputs = tf.keras.Input(shape=input_shape) \n",
    "\n",
    "# Project the inputs to the embed_dim \n",
    "x = tf.keras.layers.Dense(embed_dim)(inputs) \n",
    "encoder_outputs = transformer_encoder(x) \n",
    "flatten = tf.keras.layers.Flatten()(encoder_outputs) \n",
    "outputs = tf.keras.layers.Dense(1)(flatten) \n",
    "model = tf.keras.Model(inputs, outputs) \n",
    "\n",
    "# Compile the model \n",
    "model.compile(optimizer='adam', loss='mse') \n",
    "\n",
    "# Summary of the model \n",
    "model.summary() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "- The Transformer Encoder model defines the necessary parameters, flattens the output, and ends with a dense layer to produce the final output.  \n",
    "\n",
    "- The model is then compiled with the Adam optimizer and mean squared error loss. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Train the Transformer model \n",
    "\n",
    "Train the model on the prepared dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 1s/step - loss: 3.4866  \n",
      "Epoch 2/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - loss: 0.1816 \n",
      "Epoch 3/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - loss: 0.1528 \n",
      "Epoch 4/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - loss: 0.1636 \n",
      "Epoch 5/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - loss: 0.1265 \n",
      "Epoch 6/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - loss: 0.1419 \n",
      "Epoch 7/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - loss: 0.1521 \n",
      "Epoch 8/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - loss: 0.1240 \n",
      "Epoch 9/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - loss: 0.1245 \n",
      "Epoch 10/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - loss: 0.1255 \n",
      "Epoch 11/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - loss: 0.1070 \n",
      "Epoch 12/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - loss: 0.0874 \n",
      "Epoch 13/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - loss: 0.0733 \n",
      "Epoch 14/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - loss: 0.0668 \n",
      "Epoch 15/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - loss: 0.0515 \n",
      "Epoch 16/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - loss: 0.0546 \n",
      "Epoch 17/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - loss: 0.0564 \n",
      "Epoch 18/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - loss: 0.0322 \n",
      "Epoch 19/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - loss: 0.0280 \n",
      "Epoch 20/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - loss: 0.0204 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x72e1a427bda0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X, Y, epochs=20, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "The model is trained on the normalized stock price data for 20 epochs with a batch size of 32. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Evaluate and Make Predictions \n",
    "\n",
    "Evaluate the model's performance and make predictions on the dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 332ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make predictions \n",
    "predictions = model.predict(X) \n",
    "predictions = scaler.inverse_transform(predictions) \n",
    "\n",
    "# Prepare true values for comparison\n",
    "true_values = scaler.inverse_transform(data.reshape(-1, 1))\n",
    "\n",
    "# Plot the predictions vs true values\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.plot(true_values, label='True Data') \n",
    "plt.plot(np.arange(time_step, time_step + len(predictions)), predictions, label='Predictions') \n",
    "plt.xlabel('Time') \n",
    "plt.ylabel('Stock Price') \n",
    "plt.legend() \n",
    "plt.title('Predictions vs True Data (Both Scaled Back)')\n",
    "plt.show() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "- The model's predictions are transformed back to the original scale using the inverse transform of the scaler. \n",
    "\n",
    "- The true data and predictions are plotted to visualize the model's performance. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice Exercises: \n",
    "\n",
    " ### Exercise 1: Add dropout to the Transformer model \n",
    "\n",
    " **Objective: Understand how to add dropout layers to the Transformer model to prevent overfitting.** \n",
    "\n",
    " Instructions: \n",
    "\n",
    "- Add a dropout layer after the Flatten layer in the model. \n",
    "\n",
    "- Set the dropout rate to 0.5. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_13\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_13\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_74 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">793,088</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12800</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12800</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_75 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,801</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_9 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_74 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │           \u001b[38;5;34m256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m793,088\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12800\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_27 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12800\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_75 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │        \u001b[38;5;34m12,801\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">806,145</span> (3.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m806,145\u001b[0m (3.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">806,145</span> (3.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m806,145\u001b[0m (3.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Write your code here.\n",
    "# Define the necessary parameters \n",
    "\n",
    "embed_dim = 128 \n",
    "num_heads = 8 \n",
    "ff_dim = 512 \n",
    "num_layers = 4 \n",
    "\n",
    "# Define the Transformer Encoder \n",
    "transformer_encoder = TransformerEncoder(num_layers, embed_dim, num_heads, ff_dim) \n",
    "\n",
    "# Build the model \n",
    "input_shape = (X.shape[1], X.shape[2]) \n",
    "inputs = tf.keras.Input(shape=input_shape) \n",
    "\n",
    "# Project the inputs to the embed_dim \n",
    "x = tf.keras.layers.Dense(embed_dim)(inputs) \n",
    "encoder_outputs = transformer_encoder(x) \n",
    "flatten = tf.keras.layers.Flatten()(encoder_outputs) \n",
    "dropout = tf.keras.layers.Dropout(0.5)(flatten)\n",
    "outputs = tf.keras.layers.Dense(1)(dropout) \n",
    "model = tf.keras.Model(inputs, outputs) \n",
    "\n",
    "# Compile the model \n",
    "model.compile(optimizer='adam', loss='mse') \n",
    "\n",
    "# Summary of the model \n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here to view the solution.</summary>\n",
    "\n",
    "```\n",
    "from tensorflow.keras.layers import Dropout \n",
    "\n",
    "  \n",
    "\n",
    "# Add a dropout layer after the Flatten layer \n",
    "\n",
    "flatten = tf.keras.layers.Flatten()(encoder_outputs) \n",
    "\n",
    "dropout = Dropout(0.5)(flatten) \n",
    "\n",
    "outputs = tf.keras.layers.Dense(1)(dropout) \n",
    "\n",
    "  \n",
    "\n",
    "# Build the model \n",
    "\n",
    "model = tf.keras.Model(inputs, outputs) \n",
    "\n",
    "  \n",
    "\n",
    "# Compile the model \n",
    "\n",
    "model.compile(optimizer='adam', loss='mse') \n",
    "\n",
    "  \n",
    "\n",
    "# Train the model \n",
    "\n",
    "model.fit(X, Y, epochs=20, batch_size=32) \n",
    "\n",
    "  \n",
    "\n",
    "# Evaluate the model \n",
    "\n",
    "loss = model.evaluate(X, Y) \n",
    "\n",
    "print(f'Test loss: {loss}') \n",
    "\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Experiment with different batch sizes \n",
    "\n",
    "**Objective: Observe the impact of different batch sizes on model performance.** \n",
    "\n",
    " Instructions: \n",
    "\n",
    "- Train the model with a batch size of 16. \n",
    "\n",
    "- Train the model with a batch size of 64. \n",
    "\n",
    "- Compare the training time and performance. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 664ms/step - loss: 3.8314  \n",
      "Epoch 2/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 649ms/step - loss: 1.7164 \n",
      "Epoch 3/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 647ms/step - loss: 0.6361 \n",
      "Epoch 4/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 646ms/step - loss: 0.1407 \n",
      "Epoch 5/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 645ms/step - loss: 0.0565 \n",
      "Epoch 6/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 641ms/step - loss: 0.0368 \n",
      "Epoch 7/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 643ms/step - loss: 0.0381 \n",
      "Epoch 8/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 645ms/step - loss: 0.0332 \n",
      "Epoch 9/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 640ms/step - loss: 0.0292 \n",
      "Epoch 10/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 646ms/step - loss: 0.0232 \n",
      "Epoch 11/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 647ms/step - loss: 0.0213 \n",
      "Epoch 12/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 651ms/step - loss: 0.0243 \n",
      "Epoch 13/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 647ms/step - loss: 0.0252 \n",
      "Epoch 14/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 647ms/step - loss: 0.0248 \n",
      "Epoch 15/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 645ms/step - loss: 0.0238 \n",
      "Epoch 16/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 648ms/step - loss: 0.0304 \n",
      "Epoch 17/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 648ms/step - loss: 0.0232 \n",
      "Epoch 18/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 643ms/step - loss: 0.0244 \n",
      "Epoch 19/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 644ms/step - loss: 0.0243 \n",
      "Epoch 20/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 650ms/step - loss: 0.0197 \n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 323ms/step - loss: 0.0132\n",
      "Test loss with batch size 16: 0.013153742998838425\n",
      "Epoch 1/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2s/step - loss: 0.0137 \n",
      "Epoch 2/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2s/step - loss: 0.0078\n",
      "Epoch 3/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2s/step - loss: 0.0061\n",
      "Epoch 4/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 2s/step - loss: 0.0063\n",
      "Epoch 5/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2s/step - loss: 0.0060\n",
      "Epoch 6/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2s/step - loss: 0.0058\n",
      "Epoch 7/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2s/step - loss: 0.0053\n",
      "Epoch 8/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2s/step - loss: 0.0067\n",
      "Epoch 9/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 2s/step - loss: 0.0063 \n",
      "Epoch 17/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 2s/step - loss: 0.0067\n",
      "Epoch 18/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 2s/step - loss: 0.0075 \n",
      "Epoch 19/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 3s/step - loss: 0.0058 \n",
      "Epoch 20/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 2s/step - loss: 0.0049 \n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 324ms/step - loss: 5.6321e-04\n",
      "Test loss with batch size 64: 0.0005632053944282234\n"
     ]
    }
   ],
   "source": [
    "## Write your code here.\n",
    "model.fit(X, Y, epochs=20, batch_size=16)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with batch size 16: {loss}')\n",
    "\n",
    "model.fit(X, Y, epochs=20, batch_size=64)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with batch size 64: {loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here to view the solution.</summary>\n",
    "\n",
    "```\n",
    "# Train the model with batch size 16\n",
    "model.fit(X, Y, epochs=20, batch_size=16)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with batch size 16: {loss}')\n",
    "\n",
    "# Train the model with batch size 64\n",
    "model.fit(X, Y, epochs=20, batch_size=64)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with batch size 64: {loss}')\n",
    "\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Use a different activation function \n",
    "\n",
    " **Objective: Understand how different activation functions impact the model performance.** \n",
    "\n",
    " Instructions: \n",
    "\n",
    "- Change the activation function of the Dense layer to `tanh`. \n",
    "\n",
    "- Train and evaluate the model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_18\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_18\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_100 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">793,088</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12800</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12800</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_101 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,801</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_14 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_100 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │           \u001b[38;5;34m256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m793,088\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12800\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_37 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12800\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_101 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │        \u001b[38;5;34m12,801\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">806,145</span> (3.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m806,145\u001b[0m (3.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">806,145</span> (3.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m806,145\u001b[0m (3.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 2s/step - loss: 0.3117  \n",
      "Epoch 2/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 2s/step - loss: 0.2967\n",
      "Epoch 3/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2s/step - loss: 0.2967\n",
      "Epoch 4/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 2s/step - loss: 0.2967\n",
      "Epoch 5/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 2s/step - loss: 0.2967\n",
      "Epoch 6/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 2s/step - loss: 0.2967\n",
      "Epoch 7/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2s/step - loss: 0.2967\n",
      "Epoch 8/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 2s/step - loss: 0.2967\n",
      "Epoch 9/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 2s/step - loss: 0.2967 \n",
      "Epoch 10/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 2s/step - loss: 0.2967\n",
      "Epoch 11/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 2s/step - loss: 0.2967\n",
      "Epoch 12/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 2s/step - loss: 0.2967\n",
      "Epoch 13/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 2s/step - loss: 0.2967 \n",
      "Epoch 14/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 2s/step - loss: 0.2967\n",
      "Epoch 15/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 2s/step - loss: 0.2967 \n",
      "Epoch 16/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 2s/step - loss: 0.2967\n",
      "Epoch 17/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 2s/step - loss: 0.2967\n",
      "Epoch 18/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 2s/step - loss: 0.2967\n",
      "Epoch 19/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 2s/step - loss: 0.2967\n",
      "Epoch 20/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2s/step - loss: 0.2967\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 322ms/step - loss: 0.2967\n",
      "Test loss with batch size 64: 0.29668867588043213\n"
     ]
    }
   ],
   "source": [
    "## Write your code here.\n",
    "## Write your code here.\n",
    "# Define the necessary parameters \n",
    "\n",
    "embed_dim = 128 \n",
    "num_heads = 8 \n",
    "ff_dim = 512 \n",
    "num_layers = 4 \n",
    "\n",
    "# Define the Transformer Encoder \n",
    "transformer_encoder = TransformerEncoder(num_layers, embed_dim, num_heads, ff_dim) \n",
    "\n",
    "# Build the model \n",
    "input_shape = (X.shape[1], X.shape[2]) \n",
    "inputs = tf.keras.Input(shape=input_shape) \n",
    "\n",
    "# Project the inputs to the embed_dim \n",
    "x = tf.keras.layers.Dense(embed_dim)(inputs) \n",
    "encoder_outputs = transformer_encoder(x) \n",
    "flatten = tf.keras.layers.Flatten()(encoder_outputs) \n",
    "dropout = tf.keras.layers.Dropout(0.5)(flatten)\n",
    "outputs = tf.keras.layers.Dense(1, activation='tanh')(dropout) \n",
    "model = tf.keras.Model(inputs, outputs) \n",
    "\n",
    "# Compile the model \n",
    "model.compile(optimizer='adam', loss='mse') \n",
    "\n",
    "# Summary of the model \n",
    "model.summary() \n",
    "\n",
    "model.fit(X, Y, epochs=20, batch_size=64)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with batch size 64: {loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here to view the solution.</summary>\n",
    "\n",
    "```\n",
    "# Change the activation function of the Dense layer to tanh\n",
    "outputs = tf.keras.layers.Dense(1, activation='tanh')(flatten)\n",
    "\n",
    "# Build the model\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, Y, epochs=20, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with tanh activation: {loss}')\n",
    "\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Congratulations on completing this lab! In this lab, you have built an advanced Transformer model using Keras and applied it to a time series forecasting task. You have learned how to define and implement multi-head self-attention, Transformer blocks, encoder layers, and integrate them into a complete Transformer model. By experimenting with different configurations and training the model, you can further improve its performance and apply it to various sequential data tasks. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "prev_pub_hash": "8aae4de69f29de06e63c5f2d04ef24811d42d1553c8ac316f7ad75d55f2c2d79"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
